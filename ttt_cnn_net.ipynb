{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EBrlxgPfXUeS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86Y1IGEXXcKp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "879YJUvGXewo"
      },
      "outputs": [],
      "source": [
        "imgs = np.load('/content/drive/MyDrive/images.npy')\n",
        "lbls = np.load('/content/drive/MyDrive/labels.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "teRBPUIOXhq5"
      },
      "outputs": [],
      "source": [
        "def process_lbls(labels,partition):\n",
        "  index = 0\n",
        "  mul = 60 / partition\n",
        "  for lbl in labels:\n",
        "    i = int(lbl[1]/partition)\n",
        "    labels[index] = lbl[0] * mul + i\n",
        "    index+=1\n",
        "  return labels\n",
        "lbls = process_lbls(lbls,1)\n",
        "lbls = lbls[:,1]/1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6KD_M6iYXjpK"
      },
      "outputs": [],
      "source": [
        "imgs_train,imgs_test,lbls_train,lbls_test = train_test_split(imgs, lbls, train_size=0.8, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(imgs_train, lbls_train, test_size=0.125, random_state=23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5coksMgfXsIw"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(150, 150, 1)),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"),\n",
        "    keras.layers.Conv2D(128, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.Conv2D(128, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"),\n",
        "    keras.layers.Conv2D(256, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.Conv2D(256, kernel_size=3, strides = 2, activation='relu',padding='same'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"),    \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=128, activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(units=64, activation='relu'),\n",
        "    keras.layers.Dropout(0.1),\n",
        "    keras.layers.Dense(units=720, activation='softmax'),\n",
        "  ])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hIe7FPSo80y_"
      },
      "outputs": [],
      "source": [
        "def Mean_loss(y_true, y_pred): # common sense error\n",
        "   cse = tf.reduce_mean(tf.math.minimum(\n",
        "          tf.math.abs(y_true - y_pred),\n",
        "          tf.math.abs(tf.math.minimum(y_true, y_pred) + 12 - tf.math.maximum(y_true, y_pred))))*60\n",
        "   return cse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "r5g-aXZPZFfO"
      },
      "outputs": [],
      "source": [
        "model = create_model()\n",
        "model.compile(loss= \"sparse_categorical_crossentropy\",\n",
        "            optimizer=\"sgd\",\n",
        "            metrics=['accuracy', Mean_loss]\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMeo1B0jJrku"
      },
      "outputs": [],
      "source": [
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09m4MYaQZIH-"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=400,\n",
        " validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv1DTnptpmMj"
      },
      "outputs": [],
      "source": [
        "X_new = imgs_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "print(y_proba.round(2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
