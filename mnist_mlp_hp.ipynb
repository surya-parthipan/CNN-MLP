{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1bae9675f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_train_full[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_full.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    kernel_list = hp.Choice(\"kernel_initializer\", values=[\"random_normal\", \"random_uniform\", \"zeros\", \"ones\", \"glorot_normal\", \"glorot_uniform\"])\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\", \"adadelta\", \"rmsprop\", \"adamax\", \"adagrad\"])\n",
    "    activation_list = hp.Choice(\"activation\", values=['relu', 'softmax', 'tanh', 'elu', 'sigmoid'])\n",
    "    drop_out = hp.Float(\"drop_out\", min_value=.2, max_value=1)\n",
    "    \n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adadelta\":\n",
    "        optimizer = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adamax\":\n",
    "        optimizer = tf.keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=activation_list, kernel_initializer=kernel_list))\n",
    "        model.add(tf.keras.layers.Dropout(drop_out))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 02m 26s]\n",
      "val_accuracy: 0.11763999760150909\n",
      "\n",
      "Best val_accuracy So Far: 0.842960000038147\n",
      "Total elapsed time: 03h 56m 51s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, \n",
    "    objective=\"val_accuracy\", \n",
    "    max_trials=20,\n",
    "    executions_per_trial=5,\n",
    "    overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", \n",
    "    project_name=\"HP_Fashion_MNIST\", \n",
    "    seed=42)\n",
    "\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=5)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Param 0 : \n",
      " {'n_hidden': 6, 'n_neurons': 140, 'learning_rate': 0.001462772808938758, 'kernel_initializer': 'random_uniform', 'optimizer': 'rmsprop', 'activation': 'elu', 'drop_out': 0.3066681333770488}\n",
      "\n",
      "Top Param 1 : \n",
      " {'n_hidden': 1, 'n_neurons': 117, 'learning_rate': 0.006678619769811224, 'kernel_initializer': 'glorot_normal', 'optimizer': 'adamax', 'activation': 'tanh', 'drop_out': 0.35562979834654485}\n",
      "\n",
      "Top Param 2 : \n",
      " {'n_hidden': 2, 'n_neurons': 155, 'learning_rate': 0.0009452767099282696, 'kernel_initializer': 'glorot_normal', 'optimizer': 'adagrad', 'activation': 'elu', 'drop_out': 0.2980296105401524}\n",
      "\n",
      "Top Param 3 : \n",
      " {'n_hidden': 6, 'n_neurons': 64, 'learning_rate': 0.0038287047044982298, 'kernel_initializer': 'random_uniform', 'optimizer': 'rmsprop', 'activation': 'relu', 'drop_out': 0.36293635793684126}\n",
      "\n",
      "Top Param 4 : \n",
      " {'n_hidden': 1, 'n_neurons': 135, 'learning_rate': 0.0003069273045576997, 'kernel_initializer': 'zeros', 'optimizer': 'adamax', 'activation': 'softmax', 'drop_out': 0.27227188341547964}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=5)\n",
    "for i in range(len(top3_params)):\n",
    "    print(f'Top Param {i} : \\n {top3_params[i].values}\\n')  # best hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train 0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 6\n",
      "n_neurons: 140\n",
      "learning_rate: 0.001462772808938758\n",
      "kernel_initializer: random_uniform\n",
      "optimizer: rmsprop\n",
      "activation: elu\n",
      "drop_out: 0.3066681333770488\n",
      "Score: 0.842960000038147\n",
      "--------------\n",
      "Best Train 1\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 1\n",
      "n_neurons: 117\n",
      "learning_rate: 0.006678619769811224\n",
      "kernel_initializer: glorot_normal\n",
      "optimizer: adamax\n",
      "activation: tanh\n",
      "drop_out: 0.35562979834654485\n",
      "Score: 0.754040002822876\n",
      "--------------\n",
      "Best Train 2\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 2\n",
      "n_neurons: 155\n",
      "learning_rate: 0.0009452767099282696\n",
      "kernel_initializer: glorot_normal\n",
      "optimizer: adagrad\n",
      "activation: elu\n",
      "drop_out: 0.2980296105401524\n",
      "Score: 0.6581200003623963\n",
      "--------------\n",
      "Best Train 3\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 6\n",
      "n_neurons: 64\n",
      "learning_rate: 0.0038287047044982298\n",
      "kernel_initializer: random_uniform\n",
      "optimizer: rmsprop\n",
      "activation: relu\n",
      "drop_out: 0.36293635793684126\n",
      "Score: 0.6359600067138672\n",
      "--------------\n",
      "Best Train 4\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 1\n",
      "n_neurons: 135\n",
      "learning_rate: 0.0003069273045576997\n",
      "kernel_initializer: zeros\n",
      "optimizer: adamax\n",
      "activation: softmax\n",
      "drop_out: 0.27227188341547964\n",
      "Score: 0.48948000073432923\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "best_trial= random_search_tuner.oracle.get_best_trials(num_trials=5)\n",
    "for i in range(len(best_trial)):\n",
    "    print(f'Best Train {i}')\n",
    "    best_trial[i].summary()\n",
    "    print(f'--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842960000038147"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial[0].metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 fitting on top 3 model of Hyperparameter Tuning of Fashion MNIST MLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_10 = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = CIFAR_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reshape(dataset, *size):\n",
    "    return dataset.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = data_reshape(x_train, x_train.shape[0],3072)\n",
    "x_test = data_reshape(x_test, x_test.shape[0], 3072)\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = data_reshape(x_train, x_train.shape[0],3072)\n",
    "x_test = data_reshape(x_test, x_test.shape[0], 3072)\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 22s 16ms/step - loss: 2.3041 - accuracy: 0.1032 - val_loss: 2.3047 - val_accuracy: 0.0952\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 2.2262 - accuracy: 0.1317 - val_loss: 2.0696 - val_accuracy: 0.1989\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 2.0892 - accuracy: 0.1810 - val_loss: 2.0589 - val_accuracy: 0.2002\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 2.0281 - accuracy: 0.2190 - val_loss: 1.9866 - val_accuracy: 0.2454\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 1.9801 - accuracy: 0.2416 - val_loss: 1.9367 - val_accuracy: 0.2647\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.9650 - accuracy: 0.2490 - val_loss: 1.9420 - val_accuracy: 0.2588\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 1.9599 - accuracy: 0.2498 - val_loss: 1.9303 - val_accuracy: 0.2652\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.9540 - accuracy: 0.2540 - val_loss: 1.9338 - val_accuracy: 0.2700\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.9497 - accuracy: 0.2553 - val_loss: 1.9043 - val_accuracy: 0.2889\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.9183 - accuracy: 0.2866 - val_loss: 1.8673 - val_accuracy: 0.2989\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8971 - accuracy: 0.2961 - val_loss: 1.9018 - val_accuracy: 0.3052\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8903 - accuracy: 0.3015 - val_loss: 1.8484 - val_accuracy: 0.3264\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.8863 - accuracy: 0.3022 - val_loss: 1.9001 - val_accuracy: 0.2969\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8824 - accuracy: 0.3050 - val_loss: 1.8391 - val_accuracy: 0.3311\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8759 - accuracy: 0.3066 - val_loss: 1.8450 - val_accuracy: 0.3209\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.8714 - accuracy: 0.3111 - val_loss: 1.8433 - val_accuracy: 0.3254\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8693 - accuracy: 0.3146 - val_loss: 1.8314 - val_accuracy: 0.3405\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.8556 - accuracy: 0.3244 - val_loss: 1.8339 - val_accuracy: 0.3313\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.8405 - accuracy: 0.3288 - val_loss: 1.8024 - val_accuracy: 0.3351\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8234 - accuracy: 0.3371 - val_loss: 1.8043 - val_accuracy: 0.3390\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.7791 - accuracy: 0.3479\n",
      "Test Loss : 1.7790613174438477 \n",
      " Test Accuracy : 34.790%\n"
     ]
    }
   ],
   "source": [
    "# Best Train 1\n",
    "n_hidden = 6\n",
    "n_neurons = 140\n",
    "learning_rate = 0.001462772808938758\n",
    "kernel_initializer ='random_uniform'\n",
    "optimizer = 'rmsprop'\n",
    "activation = 'elu'\n",
    "drop_out = 0.3066681333770488\n",
    "# Score: 0.842960000038147\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(n_hidden):\n",
    "    model.add(tf.keras.layers.Dense(n_neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(tf.keras.layers.Dropout(drop_out))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, validation_split=0.2)\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss : {test_loss} \\n Test Accuracy : {test_accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 2.1479 - accuracy: 0.2395 - val_loss: 2.0317 - val_accuracy: 0.2933\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 14s 12ms/step - loss: 1.9833 - accuracy: 0.2988 - val_loss: 1.9474 - val_accuracy: 0.3172\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.9272 - accuracy: 0.3212 - val_loss: 1.9109 - val_accuracy: 0.3218\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8962 - accuracy: 0.3347 - val_loss: 1.8870 - val_accuracy: 0.3449\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8740 - accuracy: 0.3436 - val_loss: 1.8683 - val_accuracy: 0.3453\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.8560 - accuracy: 0.3501 - val_loss: 1.8548 - val_accuracy: 0.3620\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.8406 - accuracy: 0.3574 - val_loss: 1.8385 - val_accuracy: 0.3603\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.8296 - accuracy: 0.3600 - val_loss: 1.8318 - val_accuracy: 0.3659\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.8189 - accuracy: 0.3652 - val_loss: 1.8182 - val_accuracy: 0.3680\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8078 - accuracy: 0.3682 - val_loss: 1.8169 - val_accuracy: 0.3621\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.7999 - accuracy: 0.3732 - val_loss: 1.8042 - val_accuracy: 0.3688\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7936 - accuracy: 0.3763 - val_loss: 1.8044 - val_accuracy: 0.3737\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 16s 12ms/step - loss: 1.7875 - accuracy: 0.3784 - val_loss: 1.7935 - val_accuracy: 0.3762\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7819 - accuracy: 0.3799 - val_loss: 1.7959 - val_accuracy: 0.3783\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 14s 12ms/step - loss: 1.7775 - accuracy: 0.3827 - val_loss: 1.7896 - val_accuracy: 0.3795\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7747 - accuracy: 0.3850 - val_loss: 1.7827 - val_accuracy: 0.3812\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7692 - accuracy: 0.3865 - val_loss: 1.7781 - val_accuracy: 0.3837\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 14s 12ms/step - loss: 1.7656 - accuracy: 0.3885 - val_loss: 1.7763 - val_accuracy: 0.3825\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 15s 12ms/step - loss: 1.7612 - accuracy: 0.3913 - val_loss: 1.7782 - val_accuracy: 0.3825\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.7598 - accuracy: 0.3898 - val_loss: 1.7747 - val_accuracy: 0.3860\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.7514 - accuracy: 0.3929\n",
      "Test Loss : 1.751367211341858 \n",
      " Test Accuracy : 39.290%\n"
     ]
    }
   ],
   "source": [
    "# Best Train 1\n",
    "n_hidden = 1\n",
    "n_neurons = 117\n",
    "learning_rate = 0.006678619769811224\n",
    "kernel_initializer = 'glorot_normal'\n",
    "optimizer = 'adamax'\n",
    "activation = 'tanh'\n",
    "drop_out = 0.35562979834654485\n",
    "# Score = 0.754040002822876\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(n_hidden):\n",
    "    model.add(tf.keras.layers.Dense(n_neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(tf.keras.layers.Dropout(drop_out))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, validation_split=0.2)\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss : {test_loss} \\n Test Accuracy : {test_accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 2.3024 - accuracy: 0.1028 - val_loss: 2.3023 - val_accuracy: 0.1124\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.3022 - accuracy: 0.1111 - val_loss: 2.3021 - val_accuracy: 0.1003\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3020 - accuracy: 0.1102 - val_loss: 2.3020 - val_accuracy: 0.1122\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3018 - accuracy: 0.1176 - val_loss: 2.3018 - val_accuracy: 0.1046\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 22s 17ms/step - loss: 2.3017 - accuracy: 0.1140 - val_loss: 2.3016 - val_accuracy: 0.1061\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3015 - accuracy: 0.1213 - val_loss: 2.3015 - val_accuracy: 0.1069\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 22s 18ms/step - loss: 2.3013 - accuracy: 0.1198 - val_loss: 2.3013 - val_accuracy: 0.1055\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 2.3011 - accuracy: 0.1247 - val_loss: 2.3011 - val_accuracy: 0.1104\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 2.3009 - accuracy: 0.1324 - val_loss: 2.3009 - val_accuracy: 0.1178\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 2.3008 - accuracy: 0.1373 - val_loss: 2.3007 - val_accuracy: 0.1222\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 2.3006 - accuracy: 0.1321 - val_loss: 2.3005 - val_accuracy: 0.1252\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 2.3004 - accuracy: 0.1367 - val_loss: 2.3003 - val_accuracy: 0.1294\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 2.3002 - accuracy: 0.1411 - val_loss: 2.3001 - val_accuracy: 0.1407\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 2.3000 - accuracy: 0.1488 - val_loss: 2.2999 - val_accuracy: 0.1445\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 2.2998 - accuracy: 0.1458 - val_loss: 2.2997 - val_accuracy: 0.1506\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 2.2995 - accuracy: 0.1505 - val_loss: 2.2995 - val_accuracy: 0.1592\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.2993 - accuracy: 0.1533 - val_loss: 2.2992 - val_accuracy: 0.1589\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.2991 - accuracy: 0.1545 - val_loss: 2.2990 - val_accuracy: 0.1617\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 7s 5ms/step - loss: 2.2988 - accuracy: 0.1565 - val_loss: 2.2988 - val_accuracy: 0.1659\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 2.2986 - accuracy: 0.1613 - val_loss: 2.2985 - val_accuracy: 0.1690\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.2984 - accuracy: 0.1666\n",
      "Test Loss : 2.298417806625366 \n",
      " Test Accuracy : 16.660%\n"
     ]
    }
   ],
   "source": [
    "# Best Train 2\n",
    "n_hidden = 2\n",
    "n_neurons = 155\n",
    "learning_rate = 0.0009452767099282696\n",
    "kernel_initializer = 'glorot_normal'\n",
    "optimizer = 'adagrad'\n",
    "activation = 'elu'\n",
    "drop_out = 0.2980296105401524\n",
    "# Score = 0.6581200003623963 #16.3\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "for _ in range(n_hidden):\n",
    "    model.add(tf.keras.layers.Dense(n_neurons, activation=activation, kernel_initializer=kernel_initializer))\n",
    "    model.add(tf.keras.layers.Dropout(drop_out))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=epochs, validation_split=0.2)\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss : {test_loss} \\n Test Accuracy : {test_accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 2.298417806625366 \n",
      "Test Accuracy : 16.660%\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Loss : {test_loss} \\nTest Accuracy : {test_accuracy:.3%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4271d910d458382237d50acf2e0e3e88f0b9ae219d280a9e770ed735fa5ba00a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
