{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 15\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x2714972f160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_train_full[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = X_train_full.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "X_train_full = np.expand_dims(X_train_full, -1)\n",
    "X_test = np.expand_dims(X_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = keras.utils.to_categorical(y_train, num_classes)  # type: ignore\n",
    "# y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=3)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=32, max_value=128, step=32)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    kernel_list = hp.Choice(\"kernel_initializer\", values=[\"random_normal\", \"random_uniform\", \"zeros\", \"ones\", \"glorot_normal\", \"glorot_uniform\"])\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\", \"adadelta\", \"rmsprop\", \"adamax\", \"adagrad\"])\n",
    "    activation_list = hp.Choice(\"activation\", values=['relu', 'softmax', 'tanh', 'sigmoid'])\n",
    "    drop_out = hp.Float(\"drop_out\", min_value=.2, max_value=1)\n",
    "    # pool_size = hp.Int(\"pool_size\", min_value=2, max_value=2)\n",
    "    # kernel_size = hp.Int(\"kernel_size\", min_value=2, max_value=3)\n",
    "    input_shape = (28, 28, 1)\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adadelta\":\n",
    "        optimizer = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"adamax\":\n",
    "        optimizer = tf.keras.optimizers.Adamax(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n",
    "        \n",
    "    model = tf.keras.Sequential()\n",
    "    # model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Conv2D(n_neurons, kernel_size=(3,3), activation=activation_list, kernel_initializer=kernel_list, input_shape=(28, 28, 1)))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(tf.keras.layers.Dropout(drop_out))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 36m 48s]\n",
      "val_accuracy: 0.10012000054121017\n",
      "\n",
      "Best val_accuracy So Far: 0.8782400131225586\n",
      "Total elapsed time: 03h 48m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, \n",
    "    objective=\"val_accuracy\", \n",
    "    max_trials=10,\n",
    "    executions_per_trial=5,\n",
    "    overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", \n",
    "    project_name=\"HP_Fashion_MNIST\", \n",
    "    seed=42)\n",
    "\n",
    "random_search_tuner.search(X_train, y_train, epochs=10,\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=5)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Param 0 : \n",
      " {'n_hidden': 2, 'n_neurons': 64, 'learning_rate': 0.0038287047044982298, 'kernel_initializer': 'random_uniform', 'optimizer': 'rmsprop', 'activation': 'relu', 'drop_out': 0.36293635793684126}\n",
      "\n",
      "Top Param 1 : \n",
      " {'n_hidden': 0, 'n_neurons': 64, 'learning_rate': 0.006678619769811224, 'kernel_initializer': 'glorot_normal', 'optimizer': 'adamax', 'activation': 'tanh', 'drop_out': 0.35562979834654485}\n",
      "\n",
      "Top Param 2 : \n",
      " {'n_hidden': 0, 'n_neurons': 64, 'learning_rate': 0.0003069273045576997, 'kernel_initializer': 'zeros', 'optimizer': 'adamax', 'activation': 'softmax', 'drop_out': 0.27227188341547964}\n",
      "\n",
      "Top Param 3 : \n",
      " {'n_hidden': 1, 'n_neurons': 64, 'learning_rate': 0.000195586335667274, 'kernel_initializer': 'glorot_normal', 'optimizer': 'adam', 'activation': 'sigmoid', 'drop_out': 0.9679687441559643}\n",
      "\n",
      "Top Param 4 : \n",
      " {'n_hidden': 1, 'n_neurons': 64, 'learning_rate': 0.0006752863927347823, 'kernel_initializer': 'random_normal', 'optimizer': 'sgd', 'activation': 'sigmoid', 'drop_out': 0.7473927619296588}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=5)\n",
    "for i in range(len(top3_params)):\n",
    "    print(f'Top Param {i} : \\n {top3_params[i].values}\\n')  # best hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Train 0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 2\n",
      "n_neurons: 64\n",
      "learning_rate: 0.0038287047044982298\n",
      "kernel_initializer: random_uniform\n",
      "optimizer: rmsprop\n",
      "activation: relu\n",
      "drop_out: 0.36293635793684126\n",
      "Score: 0.8782400131225586\n",
      "--------------\n",
      "Best Train 1\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 0\n",
      "n_neurons: 64\n",
      "learning_rate: 0.006678619769811224\n",
      "kernel_initializer: glorot_normal\n",
      "optimizer: adamax\n",
      "activation: tanh\n",
      "drop_out: 0.35562979834654485\n",
      "Score: 0.8592000126838684\n",
      "--------------\n",
      "Best Train 2\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 0\n",
      "n_neurons: 64\n",
      "learning_rate: 0.0003069273045576997\n",
      "kernel_initializer: zeros\n",
      "optimizer: adamax\n",
      "activation: softmax\n",
      "drop_out: 0.27227188341547964\n",
      "Score: 0.839799988269806\n",
      "--------------\n",
      "Best Train 3\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 1\n",
      "n_neurons: 64\n",
      "learning_rate: 0.000195586335667274\n",
      "kernel_initializer: glorot_normal\n",
      "optimizer: adam\n",
      "activation: sigmoid\n",
      "drop_out: 0.9679687441559643\n",
      "Score: 0.8072399973869324\n",
      "--------------\n",
      "Best Train 4\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 1\n",
      "n_neurons: 64\n",
      "learning_rate: 0.0006752863927347823\n",
      "kernel_initializer: random_normal\n",
      "optimizer: sgd\n",
      "activation: sigmoid\n",
      "drop_out: 0.7473927619296588\n",
      "Score: 0.7311200022697448\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "best_trial= random_search_tuner.oracle.get_best_trials(num_trials=5)\n",
    "for i in range(len(best_trial)):\n",
    "    print(f'Best Train {i}')\n",
    "    best_trial[i].summary()\n",
    "    print(f'--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8782400131225586"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial[0].metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4054 - accuracy: 0.8567\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4043 - accuracy: 0.8579\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4048 - accuracy: 0.8573\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4150 - accuracy: 0.8518\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4118 - accuracy: 0.8531\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4150 - accuracy: 0.8524\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4216 - accuracy: 0.8504\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4263 - accuracy: 0.8489\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4239 - accuracy: 0.8494\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.4303 - accuracy: 0.8484\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5136 - accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 fitting on top 3 model of Hyperparameter Tuning of Fashion MNIST CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_10 = tf.keras.datasets.cifar10.load_data()\n",
    "(x_train, y_train), (x_test, y_test) = cifar_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)  # type: ignore\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1250/1250 [==============================] - 47s 37ms/step - loss: 1.6914 - accuracy: 0.3904 - val_loss: 1.4277 - val_accuracy: 0.4983\n",
      "Epoch 2/12\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 1.3667 - accuracy: 0.5178 - val_loss: 1.2605 - val_accuracy: 0.5696\n",
      "Epoch 3/12\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 1.2411 - accuracy: 0.5656 - val_loss: 1.1460 - val_accuracy: 0.6128\n",
      "Epoch 4/12\n",
      "1250/1250 [==============================] - 51s 41ms/step - loss: 1.1637 - accuracy: 0.5951 - val_loss: 1.0721 - val_accuracy: 0.6352\n",
      "Epoch 5/12\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 1.1087 - accuracy: 0.6183 - val_loss: 1.0504 - val_accuracy: 0.6403\n",
      "Epoch 6/12\n",
      "1250/1250 [==============================] - 52s 42ms/step - loss: 1.0777 - accuracy: 0.6293 - val_loss: 1.0113 - val_accuracy: 0.6577\n",
      "Epoch 7/12\n",
      "1250/1250 [==============================] - 52s 42ms/step - loss: 1.0502 - accuracy: 0.6387 - val_loss: 0.9650 - val_accuracy: 0.6696\n",
      "Epoch 8/12\n",
      "1250/1250 [==============================] - 59s 48ms/step - loss: 1.0296 - accuracy: 0.6444 - val_loss: 1.0070 - val_accuracy: 0.6498\n",
      "Epoch 9/12\n",
      "1250/1250 [==============================] - 51s 40ms/step - loss: 1.0113 - accuracy: 0.6535 - val_loss: 0.9512 - val_accuracy: 0.6763\n",
      "Epoch 10/12\n",
      "1250/1250 [==============================] - 48s 39ms/step - loss: 0.9976 - accuracy: 0.6585 - val_loss: 0.9427 - val_accuracy: 0.6882\n",
      "Epoch 11/12\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 0.9841 - accuracy: 0.6648 - val_loss: 0.8967 - val_accuracy: 0.6937\n",
      "Epoch 12/12\n",
      "1250/1250 [==============================] - 101s 81ms/step - loss: 0.9764 - accuracy: 0.6635 - val_loss: 0.9484 - val_accuracy: 0.6777\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.9433 - accuracy: 0.6902\n",
      "Test Loss : 0.9432815313339233 \n",
      " Test Accuracy : 69.020%\n"
     ]
    }
   ],
   "source": [
    "# Best model 1\n",
    "n_hidden = 2\n",
    "n_neurons = 64\n",
    "learning_rate = 0.0038287047044982298\n",
    "kernel_initializer = 'random_uniform'\n",
    "optimizer = 'rmsprop'\n",
    "activation = 'relu'\n",
    "drop_out = 0.36293635793684126\n",
    "# Score = 0.8782400131225586\n",
    "best_model_1 = tf.keras.Sequential()\n",
    "# best_model_1.add(tf.keras.layers.Flatten())\n",
    "for _ in range(n_hidden):\n",
    "    best_model_1.add(tf.keras.layers.Conv2D(n_neurons, kernel_size=(3,3), activation=activation, kernel_initializer=kernel_initializer, input_shape=(32, 32, 3)))\n",
    "    best_model_1.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    best_model_1.add(tf.keras.layers.Dropout(drop_out))\n",
    "best_model_1.add(tf.keras.layers.Flatten())\n",
    "best_model_1.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "best_model_1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "best_model_1.fit(x_train, y_train, epochs=12, validation_split=0.2)\n",
    "test_loss, test_accuracy = best_model_1.evaluate(x_test, y_test)\n",
    "print(f'Test Loss : {test_loss} \\n Test Accuracy : {test_accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.6912 - accuracy: 0.4158 - val_loss: 1.5457 - val_accuracy: 0.4756\n",
      "Epoch 2/12\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.4689 - accuracy: 0.4944 - val_loss: 1.4610 - val_accuracy: 0.5036\n",
      "Epoch 3/12\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.3800 - accuracy: 0.5271 - val_loss: 1.3900 - val_accuracy: 0.5230\n",
      "Epoch 4/12\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.3215 - accuracy: 0.5455 - val_loss: 1.3583 - val_accuracy: 0.5347\n",
      "Epoch 5/12\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2802 - accuracy: 0.5585 - val_loss: 1.3246 - val_accuracy: 0.5443\n",
      "Epoch 6/12\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2465 - accuracy: 0.5736 - val_loss: 1.3004 - val_accuracy: 0.5539\n",
      "Epoch 7/12\n",
      "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2145 - accuracy: 0.5828 - val_loss: 1.2638 - val_accuracy: 0.5689\n",
      "Epoch 8/12\n",
      "1250/1250 [==============================] - 37s 29ms/step - loss: 1.1898 - accuracy: 0.5916 - val_loss: 1.2612 - val_accuracy: 0.5650\n",
      "Epoch 9/12\n",
      "1250/1250 [==============================] - 39s 31ms/step - loss: 1.1618 - accuracy: 0.6033 - val_loss: 1.2282 - val_accuracy: 0.5774\n",
      "Epoch 10/12\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 1.1389 - accuracy: 0.6116 - val_loss: 1.2948 - val_accuracy: 0.5561\n",
      "Epoch 11/12\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1246 - accuracy: 0.6166 - val_loss: 1.2132 - val_accuracy: 0.5803\n",
      "Epoch 12/12\n",
      "1250/1250 [==============================] - 21s 17ms/step - loss: 1.1086 - accuracy: 0.6196 - val_loss: 1.2223 - val_accuracy: 0.5759\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 1.2134 - accuracy: 0.5755\n",
      "Test Loss : 1.2134066820144653 \n",
      " Test Accuracy : 57.550%\n"
     ]
    }
   ],
   "source": [
    "# Best Model 2\n",
    "n_hidden = 1\n",
    "n_neurons = 64\n",
    "learning_rate = 0.006678619769811224\n",
    "kernel_initializer = 'glorot_normal'\n",
    "optimizer = 'adamax'\n",
    "activation = 'tanh'\n",
    "drop_out = 0.35562979834654485\n",
    "# Score = 0.8592000126838684\n",
    "best_model_2 = tf.keras.Sequential()\n",
    "# best_model_2.add(tf.keras.layers.Flatten())\n",
    "for _ in range(n_hidden):\n",
    "    best_model_2.add(tf.keras.layers.Conv2D(n_neurons, kernel_size=(3,3), activation=activation, kernel_initializer=kernel_initializer, input_shape=(32, 32, 3)))\n",
    "    best_model_2.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    best_model_2.add(tf.keras.layers.Dropout(drop_out))\n",
    "best_model_2.add(tf.keras.layers.Flatten())\n",
    "best_model_2.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "best_model_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "best_model_2.fit(x_train, y_train, epochs=12, validation_split=0.2)\n",
    "test_loss, test_accuracy = best_model_2.evaluate(x_test, y_test)\n",
    "print(f'Test Loss : {test_loss} \\n Test Accuracy : {test_accuracy:.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1250/1250 [==============================] - 30s 23ms/step - loss: 2.1436 - accuracy: 0.2228 - val_loss: 2.0054 - val_accuracy: 0.2871\n",
      "Epoch 2/12\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.9278 - accuracy: 0.3268 - val_loss: 1.8750 - val_accuracy: 0.3414\n",
      "Epoch 3/12\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 1.8365 - accuracy: 0.3617 - val_loss: 1.8119 - val_accuracy: 0.3682\n",
      "Epoch 4/12\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.7851 - accuracy: 0.3792 - val_loss: 1.7718 - val_accuracy: 0.3840\n",
      "Epoch 5/12\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 1.7442 - accuracy: 0.3944 - val_loss: 1.7362 - val_accuracy: 0.3947\n",
      "Epoch 6/12\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 1.7088 - accuracy: 0.4068 - val_loss: 1.6976 - val_accuracy: 0.4140\n",
      "Epoch 7/12\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 1.6723 - accuracy: 0.4200 - val_loss: 1.6703 - val_accuracy: 0.4237\n",
      "Epoch 8/12\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.6393 - accuracy: 0.4325 - val_loss: 1.6404 - val_accuracy: 0.4253\n",
      "Epoch 9/12\n",
      "1250/1250 [==============================] - 35s 28ms/step - loss: 1.6010 - accuracy: 0.4428 - val_loss: 1.6024 - val_accuracy: 0.4400\n",
      "Epoch 10/12\n",
      "1250/1250 [==============================] - 194s 155ms/step - loss: 1.5641 - accuracy: 0.4555 - val_loss: 1.5585 - val_accuracy: 0.4607\n",
      "Epoch 11/12\n",
      "1250/1250 [==============================] - 160s 128ms/step - loss: 1.5297 - accuracy: 0.4646 - val_loss: 1.5275 - val_accuracy: 0.4700\n",
      "Epoch 12/12\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.4995 - accuracy: 0.4765 - val_loss: 1.4983 - val_accuracy: 0.4757\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 1.4768 - accuracy: 0.4773\n",
      "Test Loss : 1.4767907857894897 \n",
      " Test Accuracy : 47.730%\n"
     ]
    }
   ],
   "source": [
    "# Best Model 3\n",
    "n_hidden = 1\n",
    "n_neurons = 64\n",
    "learning_rate = 0.0003069273045576997\n",
    "kernel_initializer = 'zeros'\n",
    "optimizer = 'adamax'\n",
    "activation = 'softmax'\n",
    "drop_out = 0.27227188341547964\n",
    "# Score = 0.839799988269806\n",
    "best_model_3 = tf.keras.Sequential()\n",
    "# best_model_3.add(tf.keras.layers.Flatten())\n",
    "for _ in range(n_hidden):\n",
    "    best_model_3.add(tf.keras.layers.Conv2D(n_neurons, kernel_size=(3,3), activation=activation, kernel_initializer=kernel_initializer, input_shape=(32, 32, 3)))\n",
    "    best_model_3.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    best_model_3.add(tf.keras.layers.Dropout(drop_out))\n",
    "best_model_3.add(tf.keras.layers.Flatten())\n",
    "best_model_3.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "best_model_3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "best_model_3.fit(x_train, y_train, epochs=12, validation_split=0.2)\n",
    "test_loss, test_accuracy = best_model_3.evaluate(x_test, y_test)\n",
    "print(f'Test Loss : {test_loss} \\n Test Accuracy : {test_accuracy:.3%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4271d910d458382237d50acf2e0e3e88f0b9ae219d280a9e770ed735fa5ba00a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
